{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f604851-f8bf-4748-b3bf-f844945e246c",
   "metadata": {},
   "source": [
    "# Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580b031c-8166-47e7-b8a9-9f81ef2e6bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 14:00:24.069536: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-02 14:00:24.655375: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-02 14:00:24.659634: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 14:00:26.684192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46523574-4bca-42ce-8f9f-657f34f316eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84b0f41e-5fc6-4a0a-8ab7-4ad99ea857be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23a1fef3-86d4-4ebc-9163-6504026add6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset.map(lambda x: x * 2)\n",
    "for item in dataset1:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51605766-0bde-4f48-970d-516bf5bb9451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3d8c9c5-b2a3-4a7b-84f0-fe8279539a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = \"/\"\n",
    "\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
    "\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66b91c2c-0a62-4b2f-a64e-5e61e8bb36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean, X_std = [0.] * 8, [1.] * 8\n",
    "n_inputs = 8\n",
    "\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7edfa0e2-ba6d-474f-869e-40ea0612b74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([   4.2083,   44.    ,    5.3232,    0.9171,  856.    ,    2.337 ,\n",
       "          37.47  , -122.2   ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,856.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25dfda52-2db0-4c81-a852-7bb022fecf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                      n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                      n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads\n",
    "    )\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe871a-73a2-425a-b78a-67cfb530c73f",
   "metadata": {},
   "source": [
    "# TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "600b0ec0-0edb-4a3b-897c-f0f96769696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d7ee937-e7e2-4499-bcf1-75397f6b7a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd48b13f-537e-4995-92ea-291918037aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "# dataset = tf.data.TFRecordDataset([\"my_compressed_data.tfrecord\"], compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e48ee-7866-40ef-99f4-e502445f621d",
   "metadata": {},
   "source": [
    "## Tensorflow Protobufs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77f3b96a-e64c-4a59-94d6-f90ae078191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[\n",
    "                b\"a@b.com\",\n",
    "                b\"c@d.com\"\n",
    "            ]))\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93c5d798-91c1-4661-b9fb-0510e24d0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cfea604-7a05-4f11-905a-b31550bca8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6965a79-47b7-46cc-be19-f9d3eb975162",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8ef8234-6910-455d-b76b-d8050f1ad51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52c99b5b-d3ef-461f-a204-085f55526c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d0596-b627-4348-a101-b3337671a6f9",
   "metadata": {},
   "source": [
    "# Preprocessing Input Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43f5273c-9b92-4ae9-9e20-e3c7f2c855ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71e87a45-ef0b-4ab1-ba50-9c65f7e11749",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_layer = Standardization()\n",
    "# std_layer.adapt(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5523b9f-17a5-4444-927c-fa21cc1b8105",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3dab0c0-2df0-4653-b254-06b7490664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f1daa2c-437e-4511-a7a3-85ba5a0c9386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd21902c-05f1-45f3-99d3-a66a9d75ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4496b642-f7cc-4dc8-bb0d-fa34c6abd27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b967189f-9207-4787-b493-57320060a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afdc85e0-d5c3-42b2-8317-0127397b6a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.36121976, 0.30981433],\n",
       "       [0.09398997, 0.57039213],\n",
       "       [0.70206356, 0.68403876],\n",
       "       [0.70206356, 0.68403876]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2f8dbd7-75e8-42ea-91ee-d98e858d7061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[ 0.00970671, -0.049847  ],\n",
       "       [-0.02178693, -0.01593484],\n",
       "       [ 0.01413251, -0.00387118],\n",
       "       [ 0.01413251, -0.00387118]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets,\n",
    "                                  output_dim=embedding_dim)\n",
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15e4e4ec-a88f-4be1-a604-cf718dbe8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=7, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc2fa34-cd40-4162-8842-e349f24b6aea",
   "metadata": {},
   "source": [
    "# TFDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7653bff-effa-4042-8817-58b56dc67acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 20:59:09.487640: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/mihnea/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da47386eb674677b8f6afaa74795fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /home/mihnea/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfbc56f4-5bf2-48c0-a516-950cea8813a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
    "mnnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "424a4b16-5355-402c-b5d1-fe6471807ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR\n",
    "dataset = tfds.load(name=\"mnist\", as_supervised=True, batch_size=32)\n",
    "mnist_train = dataset[\"train\"].prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f388d73-d43e-4499-8a05-33d2064d8f6b",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd70d46e-d740-4558-9639-61ed62785bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train, X_valid = X_train_full[5000:], X_train_full[:5000]\n",
    "y_train, y_valid = y_train_full[5000:], y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "497bfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b9afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import Example, Feature, Features, Int64List, BytesList\n",
    "\n",
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label]))\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "906c4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "import os\n",
    "\n",
    "def write_tfrecords(folder_name, name, dataset, n_shards=10):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    paths = [\"{}/{}.tfrecord-{:05d}-of-{:05d}\".format(folder_name, name, index, n_shards)\n",
    "            for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                  for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "203e9c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 15:34:01.393702: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2023-10-01 15:34:21.869595: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2023-10-01 15:34:25.341673: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    }
   ],
   "source": [
    "train_filepaths = write_tfrecords(\"fashion_mnist\", \"fashion_mnist.train\", train_set)\n",
    "test_filepaths = write_tfrecords(\"fashion_mnist\", \"fashion_mnist.test\", test_set)\n",
    "valid_filepaths = write_tfrecords(\"fashion_mnist\", \"fashion_mnist.valid\", valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e83f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, [28, 28])\n",
    "    return image, example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "731604a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                 n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "    \n",
    "    if cache:\n",
    "        dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1f8b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=50000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acc4a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 28, 28), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbe837a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(y[i].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4abb527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c2d8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = Standardization(input_shape=[28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43ea80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()), axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ee93c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 16:48:50.137756: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-10-01 16:48:50.137813: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-10-01 16:48:50.137849: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-10-01 16:48:50.137861: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:186] cuptiSubscribe: ignored due to a previous error.\n",
      "2023-10-01 16:48:50.137870: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-10-01 16:48:50.137878: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1723] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-10-01 16:48:50.138111: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-10-01 16:48:50.138128: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:142] cuptiFinalize: ignored due to a previous error.\n",
      "2023-10-01 16:48:50.138131: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-10-01 16:48:50.138135: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1814] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     42/Unknown - 2s 5ms/step - loss: 1.1225 - accuracy: 0.6347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-01 16:48:52.056660: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2023-10-01 16:48:52.056743: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2023-10-01 16:48:52.056764: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.056770: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:186] cuptiSubscribe: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.056774: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.056779: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1723] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-10-01 16:48:52.062956: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2023-10-01 16:48:52.063069: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:142] cuptiFinalize: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.063078: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:459] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.063083: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_tracer.cc:1814] function cupti_interface_->Finalize()failed with error \n",
      "2023-10-01 16:48:52.065764: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.065855: E tensorflow/compiler/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-10-01 16:48:52.065943: I tensorflow/compiler/xla/backends/profiler/gpu/cupti_collector.cc:541]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2023-10-01 16:48:52.066957: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2023-10-01 16:48:52.069022: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: ./fashion_mnist_logs/run_20231001_164850/plugins/profile/2023_10_01_16_48_52/Mihnea-PC.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4651 - accuracy: 0.8423 - val_loss: 0.4190 - val_accuracy: 0.8710\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3397 - accuracy: 0.8792 - val_loss: 0.5964 - val_accuracy: 0.8714\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3141 - accuracy: 0.8925 - val_loss: 0.4712 - val_accuracy: 0.8812\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2827 - accuracy: 0.8999 - val_loss: 0.3985 - val_accuracy: 0.8766\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2526 - accuracy: 0.9070 - val_loss: 0.3623 - val_accuracy: 0.8880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7ff403dcfc70>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logs = os.path.join(os.curdir, \"fashion_mnist_logs\", \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(\n",
    "                log_dir=logs, histogram_freq=1, profile_batch=10\n",
    "                )\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b07d806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-17b0e92d6713d4be\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-17b0e92d6713d4be\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./fashion_mnist_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db07a1c",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbcf205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mihnea/.keras/datasets/aclImdb')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "FILENAME = \"aclImdb_v1.tar.gz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, extract=True)\n",
    "path = Path(filepath).parent / \"aclImdb\"\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e11aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "     return[str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4376982",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(test_valid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd028cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26810c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, 'r') as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices((tf.constant(reviews), tf.constant(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac01a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'A previous reviewer said the movie is not all that bad. What?!?!?! The movie glorifies child molestation. Oh, but Sylvia Kristel was naked in it, so let\\'s give it 5 out of 10 stars. Why not a full 10? Because the filmography was \"agonizing,\" the child\\'s looks of shock were \"unrealistic,\" and the fat friend was \"irritating.\" Nowhere in the review does the reviewer express any outrage that an American movie in 1981 featured scenes of a child having sex with a grown woman. I happened to catch this steaming loaf of a movie while staying at a hotel that had Showtime. To me, even if the fat friend had acted up a storm and was a deserving of an Oscar, I would still have to give the movie only 1 star. That TV\\'s Howard Hessman starred in the movie at the same time as he was appearing in WKRP is particularly ridiculous. But don\\'t take my word for it!', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"I can't believe that in the 34 prior comments, nobody mentioned that this film is a blatant rip-off of Born Yesterday. A man is hired to bring an ostensibly dumb blonde up to the requirements of a gangster. Hired gun and blonde fall in love and live happily ever after. Gangster is left in the lurch. But Born Yesterday was an intelligent treatment whereas this is just so much fluff. Technicolor transfer to DVD is deplorable. Natalie Kalmus would be rolling over in her grave. Check out the paperboy. Recognize him? But, it's historically interesting to see the roots of Rock 'n Roll. Also interesting is Ewell's introduction to CinemaScope, a new format at the time.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b'This movie is hilarious. The problem is that it\\'s not a comedy. One classic scene involves Kurt Thomas just happening to find a pommel-horse in the middle of a village square (which he uses to pummel the bad guys.) Another is the trek into the \"Village of Crazies.\" Too bad this movie wasn\\'t made to be a farce, or it may have gotten better ratings.', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 14:01:09.486365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-02 14:01:09.509655: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0131f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_negative, num_parallel_reads=n_read_threads)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "    \n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_positive, num_parallel_reads=n_read_threads)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "    \n",
    "    return tf.data.Dataset.concatenate(dataset_neg, dataset_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a73a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_neg, train_pos).shuffle(25000).batch(batch_size).prefetch(1)\n",
    "valid_set = imdb_dataset(valid_neg, valid_pos).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_neg, test_pos).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa733fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, n_words=50):\n",
    "    shape = tf.shape(X_batch) * tf.constant([1, 0]) + tf.constant([0, n_words])\n",
    "    Z = tf.strings.substr(X_batch, 0, 300)\n",
    "    Z = tf.strings.lower(Z)\n",
    "    Z = tf.strings.regex_replace(Z, b\"<br\\\\s*/?>\", b\" \")\n",
    "    Z = tf.strings.regex_replace(Z, b\"[^a-z]\", b\" \")\n",
    "    Z = tf.strings.split(Z)\n",
    "    return Z.to_tensor(shape=shape, default_value=b\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "865ece79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_vocabulary(data_sample, max_size=1000):\n",
    "    preprocessed_reviews = preprocess(data_sample).numpy()\n",
    "    counter = Counter()\n",
    "    for words in preprocessed_reviews:\n",
    "        for word in words:\n",
    "            if word != b\"<pad>\":\n",
    "                counter[word] += 1\n",
    "    return [b\"<pad>\"] + [word for word in counter.most_common(max_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03232246",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextVectorization(keras.layers.Layer):\n",
    "    def __init__(self, max_vocabulary_size=1000, n_oov_buckets=100, dtype=tf.string, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        self.max_vocabulary_size = max_vocabulary_size\n",
    "        self.n_oov_buckets = n_oov_buckets\n",
    "        \n",
    "    def adapt(self, data_sample):\n",
    "        self.vocab = get_vocabulary(data_sample, self.max_vocabulary_size)\n",
    "        words = tf.constant(self.vocab)\n",
    "        word_ids = tf.range(len(self.vocab), dtype=tf.int64)\n",
    "        vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "        self.table = tf.lookup.StaticVocabularyTable(vocab_init, self.n_oov_buckets)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed_inputs = preprocess(inputs)\n",
    "        return self.table.lookup(preprocessed_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc3f725f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert Python sequence with mixed types to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_541/968895752.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtext_vectorization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_vocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_oov_buckets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtext_vectorization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_541/4206222098.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data_sample)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_vocabulary_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mword_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvocab_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyValueTensorInitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/ai/env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m--> 263\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    264\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/ai/env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   const_tensor = ops._create_graph_constant(  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/personal/ai/env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/personal/ai/env/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
     ]
    }
   ],
   "source": [
    "max_vocabulary_size = 1000\n",
    "n_oov_buckets = 100\n",
    "\n",
    "sample_review_batches = train_set.map(lambda review, label: review).take(1)\n",
    "sample_reviews = np.concatenate(list(sample_review_batches.as_numpy_iterator()), axis=0)\n",
    "\n",
    "text_vectorization = TextVectorization(max_vocabulary_size, n_oov_buckets, input_shape=[])\n",
    "text_vectorization.adapt(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d99d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
